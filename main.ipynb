{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fe15c1-f5a1-422f-ad6c-cd7c4867d616",
   "metadata": {},
   "source": [
    "# **Proyecto 02: Clasificación Supervisada**\n",
    "\n",
    "---\n",
    "\n",
    "### **Integrantes**:\n",
    "- Kalos Lazo\n",
    "- Benjamín Soto\n",
    "- Lucas Carranza\n",
    "- José Osnayo\n",
    "\n",
    "---\n",
    "\n",
    "### **Importar librerías escenciales**\n",
    "\n",
    "A continuación se importarán las librerías escenciales para proceder con nuestro análisis exploratorio de datos (EDA), los archivos utilizan el formato `.h5` destinado para trabajar con archivos complejos, se procederá a utilizar la librería `h5py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08854a42-5d10-4b31-8f32-f3d4c1b71425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51103abe-9e9f-4492-8024-ec0953c60216",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Data**\n",
    "\n",
    "Considerando que dentro de nuestra estructura contamos con una carpeta de datos en la localización raíz `/data`, importamos los archivos train y test para entrenamiento y testeo respectivamente.\n",
    "\n",
    "Se procede a crear una [función](https://stackoverflow.com/questions/28170623/how-to-read-hdf5-files-in-python) para convertir de nuestros archivos de `.h5` a un pandas dataframe, de tal forma que podamos utilizar nuestros datos al aplicar el modelo. La función toma la ubicación del archivo y convierte cada dataset en un elemento del tipo numpy array, posteriormente se instancia como un objeto pandas dataframe.\n",
    "\n",
    "Por último una vez tenemos un diccionario de dataframes, se hace esto para mantener el nombre de cada dataset para un posterior análisis y correctitud. Esto se logra al ver que al sacar las features y juntar todas las características necesitamos un mecanismo que diferencie entre las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd57c511-21c8-4a88-acfa-e97cba494ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claves de columnas en train_data\n",
      ": dict_keys(['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z', 'y'])\n",
      "\n",
      "Claves de columnas en test_data\n",
      ": dict_keys(['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z'])\n"
     ]
    }
   ],
   "source": [
    "def file_data_processing(path):\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        return {each_dataset: pd.DataFrame(hf[each_dataset][()]) for each_dataset in hf}\n",
    "\n",
    "path = './data/'\n",
    "train_path = f'{path}/train.h5'\n",
    "test_path = f'{path}/test.h5'\n",
    "\n",
    "train_data = file_data_processing(train_path)\n",
    "test_data = file_data_processing(test_path)\n",
    "\n",
    "print(\"Claves de columnas en train_data\\n:\", train_data.keys())\n",
    "print(\"\\nClaves de columnas en test_data\\n:\", test_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d4ab0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Extracción de características**\n",
    "\n",
    "Hasta ahora contamos con una matriz de matrices, donde en cada uno de sus hijos interiores representa un dataset del usuario para una respectiva acción con sus EEG, por ejemplo el de caminar hacia arriba, caminar hacia abajo, entre otras.\n",
    "\n",
    "Al tener 128 características por lo que debemos inicialmente reducir la dimensionalidad, utilizaremos la reducción por LDA (Linear Discriminant Analysis), una vez logramos esto individualmente, procedemos a juntarlos todos en una matriz. Si no hicieramos esta reducción trabajaríamos con una matriz de $128 \\cdot 9 = 1152$ características. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3c1227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:04<00:00, 1533.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_acc_x: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:03<00:00, 1947.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_acc_y: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:03<00:00, 2153.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_acc_z: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:02<00:00, 2636.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_gyro_x: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:02<00:00, 2768.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_gyro_y: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:02<00:00, 2814.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_gyro_z: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:02<00:00, 2665.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en total_acc_x: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:02<00:00, 2812.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en total_acc_y: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 7352/7352 [00:03<00:00, 2406.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en total_acc_z: (7352, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 2546.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_acc_x: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 2149.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_acc_y: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 2547.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_acc_z: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 1944.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_gyro_x: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 1902.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_gyro_y: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 1833.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en body_gyro_z: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 2515.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en total_acc_x: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 2397.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en total_acc_y: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 2947/2947 [00:01<00:00, 2441.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de características extraídas en total_acc_z: (2947, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def dataset_descriptive_features(df, dataset_name):\n",
    "    df_conversion_long = df.copy();\n",
    "    df_conversion_long['id'] = df.index;\n",
    "    df_conversion_long = df_conversion_long.melt(id_vars=['id'], var_name='time', value_name='value')\n",
    "\n",
    "    # Seleccionando parámetros a extraer\n",
    "    to_extract = MinimalFCParameters()\n",
    "    del to_extract[\"length\"] # Removiendo parámetros inservibles\n",
    "    \n",
    "    extracted_features = extract_features(df_conversion_long, column_id = 'id', column_sort = 'time',  default_fc_parameters = to_extract, n_jobs=0)\n",
    "    extracted_features.columns = [f\"{dataset_name}_{each_col}\" for each_col in extracted_features.columns]\n",
    "    \n",
    "    return extracted_features\n",
    "\n",
    "def get_datasets_features(train_data):\n",
    "    features_list = [];\n",
    "    for name, df in train_data.items():\n",
    "        if name != 'y':\n",
    "            extracted_features = dataset_descriptive_features(df, name)\n",
    "            print(f\"Dimension de características extraídas en {name}: {extracted_features.shape}\")\n",
    "            features_list.append(extracted_features)\n",
    "    return features_list;\n",
    "\n",
    "x_train_features = get_datasets_features(train_data);\n",
    "x_test_features = get_datasets_features(test_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce365de1",
   "metadata": {},
   "source": [
    "Con la función anterior, `descriptive_features`, se logra obtener las características más importantes y descriptivas de cada dataset. Podríamos hacerlo manual obteniendo mediana, mínimo, máximo, entre otros, pero para este caso ya utilizamos funcionalidad hecha por la librería de [TsFresh](https://tsfresh.readthedocs.io/en/latest/): extrae automáticamente [características importantes](https://www.linkedin.com/pulse/unlocking-time-series-insights-tsfresh-python-guide-rany-5yr7c/) acerca de una serie temporal.\n",
    "\n",
    "Para aplicar este método primero debe convertirse el dataframe a un formato largo (long) que es exigido por la librería, se basa en una matriz tal que cada fila es una observación y cada columna un momento del tiempo, posteriormente ese train data sera dividido para el eje X, Y. El resultado esperado en `x_train_features` es almacenar una lista con las features más importantes obtenidas de cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c5b1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de X_train: (7352, 81)\n",
      "Dimensiones de Y_train: (7352, 1)\n",
      "Dimensiones de X_test: (2947, 81)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat(x_train_features, axis = 1).dropna(axis = 1).reset_index(drop = True)\n",
    "Y_train = pd.DataFrame(train_data['y'].to_numpy().flatten())\n",
    "\n",
    "X_test = pd.concat(x_test_features, axis=1).dropna(axis=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensiones de Y_train: {Y_train.shape}\")\n",
    "print(f\"Dimensiones de X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b04d13-22ab-4307-bacb-d658376653f0",
   "metadata": {},
   "source": [
    "Una vez realizado este proceso contaremos con nuevas columnas en nuestro `X_train`, pues hemos aplicado una funcionalidad de la librería TsFresh y hemos escarbado la información más importante de nuestra serie de tiempo (*time series*). Cabe resaltar que `X_train` está concatenando múltiples Dataframes en uno solo: `x_train_features`, la opción `axis = 1` indica que será por medio de las columnas, se eliminan las columnas con valores `NaN` y se elimina el indice anterior. En el caso de Y sólo se convierte en vector unidimensional con `flatten`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9480b6a-2b96-463e-b9c5-8b5fb21973f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body_acc_x_value__sum_values', 'body_acc_x_value__median',\n",
       "       'body_acc_x_value__mean', 'body_acc_x_value__standard_deviation',\n",
       "       'body_acc_x_value__variance', 'body_acc_x_value__root_mean_square',\n",
       "       'body_acc_x_value__maximum', 'body_acc_x_value__absolute_maximum',\n",
       "       'body_acc_x_value__minimum', 'body_acc_y_value__sum_values',\n",
       "       'body_acc_y_value__median', 'body_acc_y_value__mean',\n",
       "       'body_acc_y_value__standard_deviation', 'body_acc_y_value__variance',\n",
       "       'body_acc_y_value__root_mean_square', 'body_acc_y_value__maximum',\n",
       "       'body_acc_y_value__absolute_maximum', 'body_acc_y_value__minimum',\n",
       "       'body_acc_z_value__sum_values', 'body_acc_z_value__median',\n",
       "       'body_acc_z_value__mean', 'body_acc_z_value__standard_deviation',\n",
       "       'body_acc_z_value__variance', 'body_acc_z_value__root_mean_square',\n",
       "       'body_acc_z_value__maximum', 'body_acc_z_value__absolute_maximum',\n",
       "       'body_acc_z_value__minimum', 'body_gyro_x_value__sum_values',\n",
       "       'body_gyro_x_value__median', 'body_gyro_x_value__mean',\n",
       "       'body_gyro_x_value__standard_deviation', 'body_gyro_x_value__variance',\n",
       "       'body_gyro_x_value__root_mean_square', 'body_gyro_x_value__maximum',\n",
       "       'body_gyro_x_value__absolute_maximum', 'body_gyro_x_value__minimum',\n",
       "       'body_gyro_y_value__sum_values', 'body_gyro_y_value__median',\n",
       "       'body_gyro_y_value__mean', 'body_gyro_y_value__standard_deviation',\n",
       "       'body_gyro_y_value__variance', 'body_gyro_y_value__root_mean_square',\n",
       "       'body_gyro_y_value__maximum', 'body_gyro_y_value__absolute_maximum',\n",
       "       'body_gyro_y_value__minimum', 'body_gyro_z_value__sum_values',\n",
       "       'body_gyro_z_value__median', 'body_gyro_z_value__mean',\n",
       "       'body_gyro_z_value__standard_deviation', 'body_gyro_z_value__variance',\n",
       "       'body_gyro_z_value__root_mean_square', 'body_gyro_z_value__maximum',\n",
       "       'body_gyro_z_value__absolute_maximum', 'body_gyro_z_value__minimum',\n",
       "       'total_acc_x_value__sum_values', 'total_acc_x_value__median',\n",
       "       'total_acc_x_value__mean', 'total_acc_x_value__standard_deviation',\n",
       "       'total_acc_x_value__variance', 'total_acc_x_value__root_mean_square',\n",
       "       'total_acc_x_value__maximum', 'total_acc_x_value__absolute_maximum',\n",
       "       'total_acc_x_value__minimum', 'total_acc_y_value__sum_values',\n",
       "       'total_acc_y_value__median', 'total_acc_y_value__mean',\n",
       "       'total_acc_y_value__standard_deviation', 'total_acc_y_value__variance',\n",
       "       'total_acc_y_value__root_mean_square', 'total_acc_y_value__maximum',\n",
       "       'total_acc_y_value__absolute_maximum', 'total_acc_y_value__minimum',\n",
       "       'total_acc_z_value__sum_values', 'total_acc_z_value__median',\n",
       "       'total_acc_z_value__mean', 'total_acc_z_value__standard_deviation',\n",
       "       'total_acc_z_value__variance', 'total_acc_z_value__root_mean_square',\n",
       "       'total_acc_z_value__maximum', 'total_acc_z_value__absolute_maximum',\n",
       "       'total_acc_z_value__minimum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4af39-fe4f-469f-bc93-df68be944c73",
   "metadata": {},
   "source": [
    "En este caso podemos ver cómo reducimos la complejidad ahora con $90$ columnas de las cuales tenemos la información escencial de las líneas de tiempo, que anteriormente eran $128 \\cdot 9$. Con esta información nuestro modelo ya puede empezar a ser entrenado. Se verifica posteriormente que se preservan las filas iniciales, en este caso $7352$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3719a6-77f7-4750-b653-f9a48cc18be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_acc_x_value__sum_values</th>\n",
       "      <th>body_acc_x_value__median</th>\n",
       "      <th>body_acc_x_value__mean</th>\n",
       "      <th>body_acc_x_value__standard_deviation</th>\n",
       "      <th>body_acc_x_value__variance</th>\n",
       "      <th>body_acc_x_value__root_mean_square</th>\n",
       "      <th>body_acc_x_value__maximum</th>\n",
       "      <th>body_acc_x_value__absolute_maximum</th>\n",
       "      <th>body_acc_x_value__minimum</th>\n",
       "      <th>body_acc_y_value__sum_values</th>\n",
       "      <th>...</th>\n",
       "      <th>total_acc_y_value__minimum</th>\n",
       "      <th>total_acc_z_value__sum_values</th>\n",
       "      <th>total_acc_z_value__median</th>\n",
       "      <th>total_acc_z_value__mean</th>\n",
       "      <th>total_acc_z_value__standard_deviation</th>\n",
       "      <th>total_acc_z_value__variance</th>\n",
       "      <th>total_acc_z_value__root_mean_square</th>\n",
       "      <th>total_acc_z_value__maximum</th>\n",
       "      <th>total_acc_z_value__absolute_maximum</th>\n",
       "      <th>total_acc_z_value__minimum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.290392</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>-0.211888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132631</td>\n",
       "      <td>12.765670</td>\n",
       "      <td>0.099841</td>\n",
       "      <td>0.099732</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.099811</td>\n",
       "      <td>0.109485</td>\n",
       "      <td>0.109485</td>\n",
       "      <td>0.088742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>-0.006706</td>\n",
       "      <td>0.048848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132631</td>\n",
       "      <td>12.408253</td>\n",
       "      <td>0.097748</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.097064</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054796</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>-0.010483</td>\n",
       "      <td>-0.156364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137142</td>\n",
       "      <td>11.890790</td>\n",
       "      <td>0.093636</td>\n",
       "      <td>0.092897</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.105788</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042157</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>-0.010483</td>\n",
       "      <td>-0.608434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143545</td>\n",
       "      <td>11.219701</td>\n",
       "      <td>0.087501</td>\n",
       "      <td>0.087654</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.087793</td>\n",
       "      <td>0.098737</td>\n",
       "      <td>0.098737</td>\n",
       "      <td>0.076888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.024980</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>-0.006847</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143545</td>\n",
       "      <td>10.879856</td>\n",
       "      <td>0.084765</td>\n",
       "      <td>0.084999</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.085077</td>\n",
       "      <td>0.093388</td>\n",
       "      <td>0.093388</td>\n",
       "      <td>0.074595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_acc_x_value__sum_values  body_acc_x_value__median  \\\n",
       "0                      0.290392                  0.002025   \n",
       "1                      0.022239                  0.000110   \n",
       "2                      0.054796                  0.000627   \n",
       "3                      0.042157                  0.000269   \n",
       "4                     -0.024980                 -0.000144   \n",
       "\n",
       "   body_acc_x_value__mean  body_acc_x_value__standard_deviation  \\\n",
       "0                0.002269                              0.002941   \n",
       "1                0.000174                              0.001981   \n",
       "2                0.000428                              0.002908   \n",
       "3                0.000329                              0.002678   \n",
       "4               -0.000195                              0.002015   \n",
       "\n",
       "   body_acc_x_value__variance  body_acc_x_value__root_mean_square  \\\n",
       "0                    0.000009                            0.003714   \n",
       "1                    0.000004                            0.001989   \n",
       "2                    0.000008                            0.002940   \n",
       "3                    0.000007                            0.002698   \n",
       "4                    0.000004                            0.002025   \n",
       "\n",
       "   body_acc_x_value__maximum  body_acc_x_value__absolute_maximum  \\\n",
       "0                   0.010810                            0.010810   \n",
       "1                   0.005251                            0.006706   \n",
       "2                   0.008167                            0.010483   \n",
       "3                   0.008167                            0.010483   \n",
       "4                   0.005650                            0.006847   \n",
       "\n",
       "   body_acc_x_value__minimum  body_acc_y_value__sum_values  ...  \\\n",
       "0                  -0.004294                     -0.211888  ...   \n",
       "1                  -0.006706                      0.048848  ...   \n",
       "2                  -0.010483                     -0.156364  ...   \n",
       "3                  -0.010483                     -0.608434  ...   \n",
       "4                  -0.006847                      0.038168  ...   \n",
       "\n",
       "   total_acc_y_value__minimum  total_acc_z_value__sum_values  \\\n",
       "0                   -0.132631                      12.765670   \n",
       "1                   -0.132631                      12.408253   \n",
       "2                   -0.137142                      11.890790   \n",
       "3                   -0.143545                      11.219701   \n",
       "4                   -0.143545                      10.879856   \n",
       "\n",
       "   total_acc_z_value__median  total_acc_z_value__mean  \\\n",
       "0                   0.099841                 0.099732   \n",
       "1                   0.097748                 0.096939   \n",
       "2                   0.093636                 0.092897   \n",
       "3                   0.087501                 0.087654   \n",
       "4                   0.084765                 0.084999   \n",
       "\n",
       "   total_acc_z_value__standard_deviation  total_acc_z_value__variance  \\\n",
       "0                               0.003970                     0.000016   \n",
       "1                               0.004918                     0.000024   \n",
       "2                               0.006145                     0.000038   \n",
       "3                               0.004945                     0.000024   \n",
       "4                               0.003637                     0.000013   \n",
       "\n",
       "   total_acc_z_value__root_mean_square  total_acc_z_value__maximum  \\\n",
       "0                             0.099811                    0.109485   \n",
       "1                             0.097064                    0.105788   \n",
       "2                             0.093100                    0.105788   \n",
       "3                             0.087793                    0.098737   \n",
       "4                             0.085077                    0.093388   \n",
       "\n",
       "   total_acc_z_value__absolute_maximum  total_acc_z_value__minimum  \n",
       "0                             0.109485                    0.088742  \n",
       "1                             0.105788                    0.081100  \n",
       "2                             0.105788                    0.081100  \n",
       "3                             0.098737                    0.076888  \n",
       "4                             0.093388                    0.074595  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ab3e5-d60e-4b67-9575-248aff5c5eb7",
   "metadata": {},
   "source": [
    "---\n",
    "### **Exploración de Datos**\n",
    "\n",
    "Lo primero que queremos es conocer nuestras features que previamente han sido modificados, es así que como primer paso podemos usar la función `describe()` que permite de manera sencilla obtener estadísticas descriptivas de nuestras columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b32a807-f508-4b76-bb28-d06cdd2acf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>body_acc_x_value__sum_values</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>-0.081447</td>\n",
       "      <td>1.853377</td>\n",
       "      <td>-33.700321</td>\n",
       "      <td>-0.385138</td>\n",
       "      <td>-0.010087</td>\n",
       "      <td>0.287138</td>\n",
       "      <td>19.056348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_acc_x_value__median</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>-0.024342</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>-0.285125</td>\n",
       "      <td>-0.038399</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.151517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_acc_x_value__mean</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>-0.263284</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.148878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_acc_x_value__standard_deviation</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>0.129105</td>\n",
       "      <td>0.145224</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>0.246462</td>\n",
       "      <td>0.648675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_acc_x_value__variance</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.054605</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.060744</td>\n",
       "      <td>0.420780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc_z_value__variance</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.127318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc_z_value__root_mean_square</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>0.285424</td>\n",
       "      <td>0.232424</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.125216</td>\n",
       "      <td>0.202054</td>\n",
       "      <td>0.374049</td>\n",
       "      <td>0.988379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc_z_value__maximum</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>0.245178</td>\n",
       "      <td>0.306718</td>\n",
       "      <td>-0.978027</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>0.213361</td>\n",
       "      <td>0.420355</td>\n",
       "      <td>1.281363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc_z_value__absolute_maximum</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>0.448607</td>\n",
       "      <td>0.289168</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.226644</td>\n",
       "      <td>0.402390</td>\n",
       "      <td>0.644768</td>\n",
       "      <td>1.639609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc_z_value__minimum</th>\n",
       "      <td>7352.0</td>\n",
       "      <td>-0.103294</td>\n",
       "      <td>0.488384</td>\n",
       "      <td>-1.639609</td>\n",
       "      <td>-0.400259</td>\n",
       "      <td>-0.116149</td>\n",
       "      <td>0.182312</td>\n",
       "      <td>0.965508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       count      mean       std        min  \\\n",
       "body_acc_x_value__sum_values          7352.0 -0.081447  1.853377 -33.700321   \n",
       "body_acc_x_value__median              7352.0 -0.024342  0.044907  -0.285125   \n",
       "body_acc_x_value__mean                7352.0 -0.000636  0.014480  -0.263284   \n",
       "body_acc_x_value__standard_deviation  7352.0  0.129105  0.145224   0.001413   \n",
       "body_acc_x_value__variance            7352.0  0.037755  0.054605   0.000002   \n",
       "...                                      ...       ...       ...        ...   \n",
       "total_acc_z_value__variance           7352.0  0.010558  0.015461   0.000009   \n",
       "total_acc_z_value__root_mean_square   7352.0  0.285424  0.232424   0.003700   \n",
       "total_acc_z_value__maximum            7352.0  0.245178  0.306718  -0.978027   \n",
       "total_acc_z_value__absolute_maximum   7352.0  0.448607  0.289168   0.007652   \n",
       "total_acc_z_value__minimum            7352.0 -0.103294  0.488384  -1.639609   \n",
       "\n",
       "                                           25%       50%       75%        max  \n",
       "body_acc_x_value__sum_values         -0.385138 -0.010087  0.287138  19.056348  \n",
       "body_acc_x_value__median             -0.038399 -0.001441  0.000300   0.151517  \n",
       "body_acc_x_value__mean               -0.003009 -0.000079  0.002243   0.148878  \n",
       "body_acc_x_value__standard_deviation  0.003758  0.018826  0.246462   0.648675  \n",
       "body_acc_x_value__variance            0.000014  0.000354  0.060744   0.420780  \n",
       "...                                        ...       ...       ...        ...  \n",
       "total_acc_z_value__variance           0.000033  0.000413  0.017381   0.127318  \n",
       "total_acc_z_value__root_mean_square   0.125216  0.202054  0.374049   0.988379  \n",
       "total_acc_z_value__maximum            0.042551  0.213361  0.420355   1.281363  \n",
       "total_acc_z_value__absolute_maximum   0.226644  0.402390  0.644768   1.639609  \n",
       "total_acc_z_value__minimum           -0.400259 -0.116149  0.182312   0.965508  \n",
       "\n",
       "[81 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b274c-5251-43ec-b8e6-d0741ec2bf1e",
   "metadata": {},
   "source": [
    "Antes de mostrar gráficamente estos datos, vamos a utilizar la información de `Y` que está numérica desde el `1 \\to 6` que indica la acción, por ejemplo \"WALKING\", por ello vamos a utilizar estos labels considerando el orden lógico propuesto en el enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61903be6-5c44-41ac-bdbb-fbdeb3facbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 6., 1., 3., 2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fedf1-aa76-4699-a0e8-56e54184201d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Hemos creado una función para asignar cada elemento de `Y_train` a el obtenido dentro de sus filas, de esta forma contamos las apariciones y es posible gráficamente comparar y notar que `LAYING: 5`, es el que más apareció dentro de los registros de entrenamiento. Otra cosa a mencionar es que las actividades con su etiqueta asociada están distribuidas de manera equitativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4faf5c04-9e5d-4090-a5c6-0368ffc12d71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def assign_key_labels(df, arr_to_mapped):\n",
    "    activities_map = {i+1: arr_to_mapped[i] for i in range(len(arr_to_mapped))}\n",
    "    activities_mapped = df[0].map(activities_map);\n",
    "    df_mapped = pd.DataFrame({'Activity': activities_mapped});\n",
    "    \n",
    "    return df_mapped;\n",
    "    \n",
    "labels_actions = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "Y_train_label = assign_key_labels(Y_train, labels_actions)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(x='Activity', data=Y_train_label, order=labels_actions)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Gráfico comparativo de cuenta de actividades en X_train')\n",
    "plt.xlabel('Nombre de Actividad')\n",
    "plt.ylabel('Conteo de aparición')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e2a9e-3483-4568-98aa-97ed48c025c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Procesamiento de datos**\n",
    "\n",
    "Ahora, se procede con la división de los conjuntos de datos usando el método de remuestreo de k-fold validation. En este caso se eligirán 10 pliegues, donde 1 de ellos será usado para validación en cada uno de los modelos de clasificación.\n",
    "\n",
    "Para esto se obtiene el número de filas de los datos de entrenamiento originales, para iterar a través de ellos insertando cada décimo de las filas en 2 listas de pliegues, una para los x y otra para los y. Luego a la hora de ejecutar los modelos se hacen 10 iteraciones donde la i-ésima matriz del X y Y se elige como datos de validación, mientras el esto de pliegues se convierten en datos de entrenamiento. Finalmente se predice en base a ellas, guardando la predicción de cada experimento, siendo la precisión final el promedio de las precisiones de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d6d5655-e549-4cdb-bd86-74a44e420481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjosn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "n = X_train.shape[0]\n",
    "n = int(n)\n",
    "# 10 pliegues\n",
    "f = int(n/10)\n",
    "folds_xtrain = []\n",
    "folds_ytrain = []\n",
    "for i in range(0,10):\n",
    "    folds_xtrain.append(X_train[i*f:(i+1)*f,:])\n",
    "    folds_ytrain.append(Y_train[i*f:(i+1)*f,:])\n",
    "scaler = StandardScaler()\n",
    "folds_xtrain = np.array(folds_xtrain)\n",
    "folds_ytrain = np.array(folds_ytrain)\n",
    "for i in range(0,10):\n",
    "    folds_xtrain[i] = scaler.fit_transform(folds_xtrain[i])\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa743e4-b7d1-422a-bdc9-f6c823ce8178",
   "metadata": {},
   "source": [
    "## Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14969e91-9c6b-4dcf-af47-fcd5e60996d2",
   "metadata": {},
   "source": [
    "### **Modelo 1: K-NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca785654-5e0f-4e79-bdbb-73548d1d29df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.linalg.norm(p1 - p2, 2)\n",
    "\n",
    "\n",
    "class KdNode:\n",
    "\n",
    "    def __init__(self, point, label, idx_column):\n",
    "        self.point = point\n",
    "        self.idx_column = idx_column\n",
    "        self.label = label\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def show(self):\n",
    "        print(self.point)\n",
    "        print(self.label)\n",
    "\n",
    "\n",
    "\n",
    "class KdTree:\n",
    "    def __init__(self, data_points):\n",
    "        self.data_points = data_points\n",
    "        self.root = self._build_tree(data_points=data_points, depth=0)\n",
    "\n",
    "    def _build_tree(self, data_points, depth):\n",
    "        \"\"\"\n",
    "            Construct a KdTree with a set of data points.\n",
    "        :param data_points: a dataframe containing data points.\n",
    "        :param depth: actual depth of the tree.\n",
    "        :return: A KdNode object.\n",
    "        \"\"\"\n",
    "        if len(data_points) == 0:\n",
    "            return None\n",
    "\n",
    "        idx_column = depth % (data_points.shape[1] - 1)\n",
    "\n",
    "        data_points_sorted = data_points[np.argsort(data_points[:, idx_column])]\n",
    "\n",
    "        # sort the data_points in base of idx_column\n",
    "\n",
    "\n",
    "        n = len(data_points_sorted)\n",
    "\n",
    "        m = n // 2\n",
    "\n",
    "        # label is the last element of the array in row m\n",
    "        label_m = data_points_sorted[m, -1]\n",
    "        point = data_points_sorted[m, :-1]\n",
    "        data_left = data_points_sorted[:m]\n",
    "        data_right = data_points_sorted[m+1:]\n",
    "\n",
    "        node = KdNode(point=point , label=label_m, idx_column=idx_column)\n",
    "        node.left = self._build_tree(data_left, depth+1)\n",
    "        node.right = self._build_tree(data_right, depth+1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _knn_search(self, node, point, k, max_heap):\n",
    "        if node is None:\n",
    "            return\n",
    "        axis = node.idx_column\n",
    "        current_dist = distance(point, node.point)\n",
    "        if len(max_heap) < k:\n",
    "            heapq.heappush(max_heap, (-1 * current_dist, node))\n",
    "        elif current_dist < -1 * max_heap[0][0]:  #\n",
    "            # pop the node with minimum (-1*dist) and replace with (-current_dist , node)\n",
    "            heapq.heapreplace(max_heap, (-1 * current_dist, node))\n",
    "\n",
    "        if point[axis] < node.point[axis]:\n",
    "            close_node = node.left\n",
    "            away_node = node.right\n",
    "        else:\n",
    "            close_node = node.right\n",
    "            away_node = node.left\n",
    "\n",
    "        self._knn_search(close_node, point, k, max_heap)\n",
    "        if len(max_heap) < k or abs(point[axis] - node.point[axis]) < -1 * max_heap[0][0]:\n",
    "            self._knn_search(away_node, point, k, max_heap)\n",
    "\n",
    "    def knn(self, point, k):\n",
    "        max_heap = []\n",
    "\n",
    "        self._knn_search(self.root, point, k, max_heap)\n",
    "        labels = []\n",
    "        for neighbor in max_heap:\n",
    "            labels.append(neighbor[1].label)\n",
    "\n",
    "        cont = Counter(labels)\n",
    "\n",
    "        label, _ = cont.most_common(1)[0]\n",
    "\n",
    "        return label\n",
    "    def predict(self, x):\n",
    "      return [self.knn(row , 5) for row in x]\n",
    "\n",
    "    def print_root(self):\n",
    "      self.root.show()\n",
    "\n",
    "def norm_data(data):\n",
    "    min_val = np.min(data, axis=0)\n",
    "    max_val = np.max(data, axis=0)\n",
    "    data = (data - min_val) / (max_val - min_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73ba65a0-8825-4b6d-8ef9-309b5dca1b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de validación 0: 99.05%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.97      1.00      0.99       153\n",
      "  WALKING_UPSTAIRS       1.00      1.00      1.00       112\n",
      "WALKING_DOWNSTAIRS       1.00      0.97      0.98        98\n",
      "           SITTING       1.00      0.97      0.98       118\n",
      "          STANDING       0.98      1.00      0.99       142\n",
      "            LAYING       1.00      1.00      1.00       112\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       0.99      0.99      0.99       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 1: 98.23%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       1.00      0.98      0.99       142\n",
      "  WALKING_UPSTAIRS       0.98      1.00      0.99       118\n",
      "WALKING_DOWNSTAIRS       1.00      1.00      1.00       120\n",
      "           SITTING       0.94      0.96      0.95       106\n",
      "          STANDING       0.96      0.95      0.96       113\n",
      "            LAYING       1.00      1.00      1.00       136\n",
      "\n",
      "          accuracy                           0.98       735\n",
      "         macro avg       0.98      0.98      0.98       735\n",
      "      weighted avg       0.98      0.98      0.98       735\n",
      "\n",
      "Precisión en el conjunto de validación 2: 98.91%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.98      1.00      0.99       135\n",
      "  WALKING_UPSTAIRS       1.00      0.99      1.00       111\n",
      "WALKING_DOWNSTAIRS       1.00      0.98      0.99       106\n",
      "           SITTING       0.99      0.97      0.98       121\n",
      "          STANDING       0.97      0.99      0.98       126\n",
      "            LAYING       1.00      1.00      1.00       136\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       0.99      0.99      0.99       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 3: 99.32%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       1.00      1.00      1.00       113\n",
      "  WALKING_UPSTAIRS       1.00      1.00      1.00       117\n",
      "WALKING_DOWNSTAIRS       1.00      1.00      1.00        87\n",
      "           SITTING       1.00      0.97      0.98       144\n",
      "          STANDING       0.97      1.00      0.98       149\n",
      "            LAYING       1.00      1.00      1.00       125\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       0.99      0.99      0.99       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 4: 99.46%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       1.00      1.00      1.00       112\n",
      "  WALKING_UPSTAIRS       1.00      1.00      1.00        99\n",
      "WALKING_DOWNSTAIRS       1.00      1.00      1.00        93\n",
      "           SITTING       0.98      0.98      0.98       131\n",
      "          STANDING       0.99      0.99      0.99       161\n",
      "            LAYING       1.00      1.00      1.00       139\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       1.00      1.00      1.00       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 5: 99.32%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.95      1.00      0.98       104\n",
      "  WALKING_UPSTAIRS       1.00      0.97      0.98        87\n",
      "WALKING_DOWNSTAIRS       1.00      0.98      0.99        84\n",
      "           SITTING       1.00      1.00      1.00       136\n",
      "          STANDING       1.00      1.00      1.00       151\n",
      "            LAYING       1.00      1.00      1.00       173\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       0.99      0.99      0.99       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 6: 99.32%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.97      0.99      0.98       105\n",
      "  WALKING_UPSTAIRS       0.99      0.99      0.99        93\n",
      "WALKING_DOWNSTAIRS       1.00      0.98      0.99        90\n",
      "           SITTING       1.00      0.99      1.00       157\n",
      "          STANDING       0.99      1.00      1.00       138\n",
      "            LAYING       1.00      1.00      1.00       152\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       0.99      0.99      0.99       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 7: 99.73%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.99      1.00      1.00       133\n",
      "  WALKING_UPSTAIRS       1.00      0.99      1.00       120\n",
      "WALKING_DOWNSTAIRS       0.99      0.99      0.99       108\n",
      "           SITTING       1.00      1.00      1.00       109\n",
      "          STANDING       1.00      1.00      1.00       124\n",
      "            LAYING       1.00      1.00      1.00       141\n",
      "\n",
      "          accuracy                           1.00       735\n",
      "         macro avg       1.00      1.00      1.00       735\n",
      "      weighted avg       1.00      1.00      1.00       735\n",
      "\n",
      "Precisión en el conjunto de validación 8: 98.78%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.98      1.00      0.99       111\n",
      "  WALKING_UPSTAIRS       0.98      0.99      0.98        92\n",
      "WALKING_DOWNSTAIRS       1.00      0.97      0.98        90\n",
      "           SITTING       0.99      0.97      0.98       142\n",
      "          STANDING       0.97      0.99      0.98       146\n",
      "            LAYING       1.00      1.00      1.00       154\n",
      "\n",
      "          accuracy                           0.99       735\n",
      "         macro avg       0.99      0.99      0.99       735\n",
      "      weighted avg       0.99      0.99      0.99       735\n",
      "\n",
      "Precisión en el conjunto de validación 9: 99.86%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.99      1.00      1.00       118\n",
      "  WALKING_UPSTAIRS       1.00      0.99      1.00       122\n",
      "WALKING_DOWNSTAIRS       1.00      1.00      1.00       110\n",
      "           SITTING       1.00      1.00      1.00       122\n",
      "          STANDING       1.00      1.00      1.00       124\n",
      "            LAYING       1.00      1.00      1.00       139\n",
      "\n",
      "          accuracy                           1.00       735\n",
      "         macro avg       1.00      1.00      1.00       735\n",
      "      weighted avg       1.00      1.00      1.00       735\n",
      "\n",
      "Precisión promedio del modelo: 0.9919727891156462\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    folds_xtrain[i] = norm_data(folds_xtrain[i])\n",
    "precisiones = []\n",
    "for i in range(0,10):\n",
    "    fold_xval = folds_xtrain[i]\n",
    "    X_val = scaler.transform(fold_xval)\n",
    "    X_val_norm = norm_data(X_val)\n",
    "    x_traini = folds_xtrain\n",
    "    x_traini = np.delete(x_traini,i,0)\n",
    "    x_traini = np.vstack(x_traini)\n",
    "    Y_val = folds_ytrain[i]\n",
    "    y_traini = folds_ytrain\n",
    "    y_traini = np.delete(y_traini,i,0)\n",
    "    y_traini = np.vstack(y_traini)\n",
    "    data_points_train = np.hstack((x_traini, y_traini.reshape(-1, 1)))\n",
    "    kdtree = KdTree(data_points_train)\n",
    "    Y_pred_knn = kdtree.predict(X_val_norm)\n",
    "    accuracy_val = accuracy_score(Y_val, Y_pred_knn)\n",
    "    precisiones.append(accuracy_val)\n",
    "    print(f\"Precisión en el conjunto de validación {i+1}: {accuracy_val * 100:.2f}%\")\n",
    "    print(classification_report(Y_val, Y_pred_knn, target_names=labels_actions))\n",
    "print(f\"Precisión promedio del modelo: {np.mean(precisiones)* 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48383d98-1dbc-4f6f-89b3-3c60b60927c1",
   "metadata": {},
   "source": [
    "### **Modelo 2 (opcional): Decision Tree**\n",
    "\n",
    "El modelo de clasificación decision tree consiste en un algoritmo recursivo para clasificar datos a través de un árbol. El procedimiento se trata de dividir los datos de la forma más eficiente usando un criterio de clasificación, hasta llegar a un punto donde cada grupo contenga solo un tipo de etiqueta en los llamados nodos hoja o terminales.\n",
    "\n",
    "Para implementarlo se crean las clases nodo, split y DT(decision tree). La clase nodo define la estructura de los grupos y específicamente el nodo terminal. La clase split contiene las funciones de clasificación y se usa en el desicion tree como los nodos no terminales. La clase DT define el modelo, donde se puede elegir el criterio de clasificación ya sea por entropía o GINI, también se le pueden agregar límites a la altura del árbol y al tamaño de los grupos, contiene el algoritmo recursivo del desicion tree usando dentro las clases nodo y split.\n",
    "\n",
    "La idea es que se construya el árbol de desición con su raíz apuntando al atributo raíz del DT, para que al ingresar los datos de validación y testing, estos recorran el árbol de forma eficiente hasta llegar a su respectivo nodo terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c88dc2-df28-4960-af0d-7241813698e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 10\n",
    "MIN_SAMPLE = 3\n",
    "NINF = -float(\"inf\")\n",
    "\n",
    "def entropy(y):\n",
    "    n = len(y)\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / n\n",
    "    h = -np.sum(p * np.log2(p))\n",
    "    return h\n",
    "\n",
    "def gini(y):\n",
    "    n = len(y)\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / n\n",
    "    gini = 1 - np.sum(p**2)\n",
    "    return gini\n",
    "\n",
    "def get_info(parent_y, left_y, right_y, method=\"e\"):\n",
    "    peso_l = len(left_y) / len(parent_y)\n",
    "    peso_r = len(right_y) / len(parent_y)\n",
    "    \n",
    "    if method == \"e\":\n",
    "        return entropy(parent_y) - (peso_l*entropy(left_y) + peso_r*entropy(right_y)) \n",
    "    else:\n",
    "        return gini(parent_y) - (peso_l*gini(left_y) + peso_r*gini(right_y))\n",
    "\n",
    "# Nodo Decision o Nodo Hoja\n",
    "class Nodo:\n",
    "    def __init__(self, index=None, left=None, right=None, info=None, umbral=None):\n",
    "        self.index = index\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info = info\n",
    "        self.umbral = umbral\n",
    "\n",
    "        self.leaf = False\n",
    "        self.valor = None\n",
    "    \n",
    "    def make_leaf(self, y):\n",
    "        y = list(y)\n",
    "        self.valor = max(y, key=y.count)\n",
    "        self.leaf = True\n",
    "    \n",
    "# Clase para almacenar la informacion de un split\n",
    "class Split:\n",
    "    def __init__(self, index=None, left=None, right=None, info=NINF, umbral=None):\n",
    "        self.index = index\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info = info\n",
    "        self.umbral = umbral\n",
    "    \n",
    "    def update(self, new_index, new_left, new_right, new_info, new_umbral):\n",
    "        if new_info > self.info:\n",
    "            self.index = new_index\n",
    "            self.left = new_left\n",
    "            self.right = new_right\n",
    "            self.info = new_info\n",
    "            self.umbral = new_umbral\n",
    "\n",
    "    def to_node(self, left, right):\n",
    "        return Nodo(index=self.index, left=left, right=right, info=self.info, umbral=self.umbral)\n",
    "    \n",
    "# Arbol de Decision\n",
    "class DT:\n",
    "    def __init__(self, X, Y, max_depth=MAX_DEPTH, min_sample=MIN_SAMPLE, method=\"g\"):\n",
    "        self._max_depth = max_depth\n",
    "        self._min_sample = min_sample\n",
    "        self._method = method\n",
    "        self.root = self.build(np.concatenate((X, Y), axis=1))\n",
    "    \n",
    "    def build(self, data, depth=0):\n",
    "        # print(f\"node at depth: {depth}\")\n",
    "        X, Y = data[:, 0:-1], data[:, -1]\n",
    "        n, k = X.shape\n",
    "\n",
    "        if depth >= self._max_depth or n < self._min_sample:\n",
    "            return self._create_leaf(Y)\n",
    "\n",
    "        best_split = self.get_best_split(data, n, k)\n",
    "\n",
    "        if best_split.info <= 0:\n",
    "            return self._create_leaf(Y)\n",
    "\n",
    "        left_tree = self.build(best_split.left, depth + 1)\n",
    "        right_tree = self.build(best_split.right, depth + 1)\n",
    "        return best_split.to_node(left_tree, right_tree)\n",
    "    \n",
    "    def get_best_split(self, data, n, k): # n: numero de filas, k: numero de columnas\n",
    "        best_split = Split()\n",
    "\n",
    "        # optimizacion tomando un subset de features para los umbrales\n",
    "        features_subset = np.random.choice(range(k), int(np.sqrt(k)*1.5), replace=False)\n",
    "\n",
    "        for char_index in features_subset:\n",
    "            unique_values = np.unique(data[:, char_index])\n",
    "\n",
    "            for i in range(1, len(unique_values)):\n",
    "                umbral = (unique_values[i - 1] + unique_values[i]) / 2\n",
    "                data_left = data[data[:, char_index] <= umbral]\n",
    "                data_right = data[data[:, char_index] > umbral]\n",
    "\n",
    "                if len(data_left) == 0 or len(data_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                parent_y, left_y, right_y = data[:, -1], data_left[:, -1], data_right[:, -1]\n",
    "                info = get_info(parent_y, left_y, right_y, method=self._method)\n",
    "\n",
    "                if info > best_split.info:\n",
    "                    best_split.index = char_index\n",
    "                    best_split.left = data_left\n",
    "                    best_split.right = data_right\n",
    "                    best_split.info = info\n",
    "                    best_split.umbral = umbral\n",
    "\n",
    "        return best_split\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict_recursive(self.root, fila) for fila in X]\n",
    "        return np.array(y_pred) \n",
    "\n",
    "    def _predict_recursive(self, nodo, x):\n",
    "        if nodo.leaf:\n",
    "            return nodo.valor\n",
    "\n",
    "        # decidir el hijo por el cual seguir en el nodo decision\n",
    "        if x[nodo.index] <= nodo.umbral:\n",
    "            return self._predict_recursive(nodo.left, x)\n",
    "        else:\n",
    "            return self._predict_recursive(nodo.right, x)\n",
    "\n",
    "    def _create_leaf(self, Y):\n",
    "        leaf = Nodo()\n",
    "        leaf.make_leaf(Y)\n",
    "        return leaf\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Ejemplo de uso:\n",
    "    X = x_train\n",
    "    Y = y_train.reshape(-1, 1)\n",
    "    model = DT(X, Y) // DT(X, Y, max_depth=20, min_sample=5, method=\"e\")\n",
    "    y_pred = model.predict(x_test)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cceb9a6-1d86-4223-a82f-dbc78c49863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisiones = []\n",
    "for i in range(0,10):\n",
    "    fold_xval = folds_xtrain[i]\n",
    "    X_val = scaler.transform(fold_xval)\n",
    "    x_traini = folds_xtrain\n",
    "    x_traini = np.delete(x_traini,i,0)\n",
    "    x_traini = np.vstack(x_traini)\n",
    "    Y_val = folds_ytrain[i]\n",
    "    y_traini = folds_ytrain\n",
    "    y_traini = np.delete(y_traini,i,0)\n",
    "    y_traini = np.vstack(y_traini)\n",
    "    dt = DT(x_traini, y_traini.reshape(-1, 1), max_depth=15, method='g')\n",
    "    Y_pred_tree = dt.predict(X_val)\n",
    "    accuracy_val = accuracy_score(Y_val, Y_pred_tree)\n",
    "    precisiones.append(accuracy_val)\n",
    "    print(f\"Precisión en el conjunto de validación {i+1}: {accuracy_val * 100:.2f}%\")\n",
    "    print(classification_report(Y_val, Y_pred_tree, target_names=labels_actions))\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(confusion_matrix(Y_val, Y_pred_tree), annot=True, fmt='g', cbar=False)\n",
    "    plt.xlabel('Prediccion')\n",
    "    plt.ylabel('Valor real')\n",
    "    plt.title('Matriz de Confusion - DT')\n",
    "    plt.show()\n",
    "print(f\"Precisión promedio del modelo: {np.mean(precisiones)* 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2388651",
   "metadata": {},
   "source": [
    "---\n",
    "### **Modelo 03: Regresión logística multivariada**\n",
    "\n",
    "Para poder implementar correctamente la regresión logística que se tenía (desarrollada en laboratorios) se tuvo que modificar ciertos aspectos, dado que ahora contamos con labels del 1 al 6, es decir ya no podemos usar una clasificación binaria, si no una que involucre multivariables.\n",
    "\n",
    "El primer cambio realizado fue utilizar una **función softmax** definida como `softmax`, en lugar de una sigmoide `s`. Esto se debe a que según nuestra [investigación](https://stats.stackexchange.com/questions/233658/softmax-vs-sigmoid-function-in-logistic-classifier) notamos que la función sigmoide está restringida a una clasificación logística binaria: 2 clases, mientras que la softmax permite una clasificación de múltiples clases. Matemáticamente, este método sólo extiende la fórmula de regresión logística para $k$ clases.\n",
    "\n",
    "Para el caso de la función pérdida, apartado donde se mide el error de la predicción de clases se actualizó de binary cross entropy a cross entropy con una regularización L2 (ridge) para manejar múltiples clases, la regularización elegida tiene como objetivo penalizar grandes valores y así evitar el overfitting. Se ejecuta softmax a la hora de predecir y busca entre todas las clases de predicción la que tenga mayor probabilidad.\n",
    "\n",
    "Por otro lado, para poder utilizar las etiquetas que se indicaron en el problema, primero obtenemos los valores únicos para el eje Y, una vez los tenemos, debemos de usar un formato para entrenar las multiclases, por lo que es necesario contar con una matriz de tamaño $n x k$, siendo $n$ la cantidad de filas de $Y$, mientras que $k$ la cantidad de clases. Se traza una diagonal de $1$ para la correspondiente categoría indicando su importancia. Es decir se transforman las variables en vectores binarios $(1, 0)$ para usarse en la función pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70430028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    y = y.astype(int) - 1;\n",
    "    \n",
    "    encoded_matrix = np.zeros((y.shape[0], num_classes))\n",
    "    encoded_matrix[np.arange(y.shape[0]), y] = 1\n",
    "    return encoded_matrix\n",
    "\n",
    "class MultivariateLogisticRegression():\n",
    "    def __init__(self, alpha=0.01, epochs=10000, epsilon=0.00001, reg_ridge=0.001):\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.reg_ridge = reg_ridge\n",
    "        self.weights = None\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def loss(self, y, y_approx):\n",
    "        n = len(y)\n",
    "        y_approx = np.clip(y_approx, self.epsilon, 1 - self.epsilon)\n",
    "        L = -np.sum(y * np.log(y_approx)) / n\n",
    "        L += self.reg_ridge * np.sum(self.weights**2) / (2 * n)\n",
    "        \n",
    "        return L\n",
    "\n",
    "    def derivatives(self, x, y):\n",
    "        y_approx = self.softmax(np.dot(x, self.weights))\n",
    "        dw = np.dot(x.T, (y_approx - y)) / len(y)\n",
    "        dw += self.reg_ridge * self.weights / len(y)\n",
    "        \n",
    "        return dw\n",
    "\n",
    "    def update_parameters(self, derivatives):\n",
    "        self.weights -= self.alpha * derivatives\n",
    "\n",
    "    def train(self, x, y):\n",
    "        np.random.seed(11)\n",
    "        self.weights = np.random.rand(x.shape[1], y.shape[1])\n",
    "        loss_vec = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            y_approx = self.softmax(np.dot(x, self.weights))\n",
    "            loss_value = self.loss(y, y_approx)\n",
    "            dw = self.derivatives(x, y)\n",
    "            self.update_parameters(dw)\n",
    "            loss_vec.append(loss_value)\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f'Número de epoch #{epoch}, Valor de pérdida: {loss_value}')\n",
    "\n",
    "        return loss_vec\n",
    "\n",
    "    def predict(self, x):\n",
    "        probabilities = self.softmax(np.dot(x, self.weights))\n",
    "        \n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1440c01",
   "metadata": {},
   "source": [
    "Se procede a hacer la normalización de datos por medio de `StandardScaler()`. Además se preparan los datos, es decir por medio de la función softmax que recibe un vector $[1, 0, 0, \\dots , 0]$, y lo convierte a un vector de probabilidades donde $s = [s_1, s_2, \\dots, s_k]$ es la salida, tal que la suma de todas las clases es $1$, indicando la probabilidad de que una muestra pertenezca a cada una de las clases posibles, recordando que por el enconding las columnas indican las clases denotadas como $k$.\n",
    "\n",
    "$$\n",
    "softmax(s_i) = \\frac{e^{s_i}}{\\sum_j^c e^{s_j}}\n",
    "$$\n",
    "\n",
    "Es así que con softmax logramos tener un vector de probabilidades que nos va servir para interpretar la probabilidad de que una muestra pertenezca a una clase específica. Su implementación en [python](https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python) se realiza con el cálculo de exponenciales dividido entre su suma para convertir en decimales que indiquen probabilidad, osea suma de $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23a05de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de epoch #0, Valor de pérdida: 4.069592243465\n",
      "Número de epoch #1000, Valor de pérdida: 0.19601748194615978\n",
      "Número de epoch #2000, Valor de pérdida: 0.17965909041979314\n",
      "Número de epoch #3000, Valor de pérdida: 0.1718390126901884\n",
      "Número de epoch #4000, Valor de pérdida: 0.16682252010385842\n",
      "Número de epoch #5000, Valor de pérdida: 0.16315014104421183\n",
      "Número de epoch #6000, Valor de pérdida: 0.1602641000440054\n",
      "Número de epoch #7000, Valor de pérdida: 0.15789621231865592\n",
      "Número de epoch #8000, Valor de pérdida: 0.15589525858528439\n",
      "Número de epoch #9000, Valor de pérdida: 0.15416715148647323\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       0.93      0.94      0.94       247\n",
      "  WALKING_UPSTAIRS       0.92      0.95      0.94       200\n",
      "WALKING_DOWNSTAIRS       0.98      0.94      0.96       206\n",
      "           SITTING       0.89      0.90      0.90       262\n",
      "          STANDING       0.91      0.90      0.90       276\n",
      "            LAYING       1.00      1.00      1.00       280\n",
      "\n",
      "          accuracy                           0.94      1471\n",
      "         macro avg       0.94      0.94      0.94      1471\n",
      "      weighted avg       0.94      0.94      0.94      1471\n",
      "\n",
      "Exactitud del modelo en validación: 93.81%\n"
     ]
    }
   ],
   "source": [
    "# tecnica de división de datos en entrenamiento y validación\n",
    "labels_actions = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_split_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_split_scaled = scaler.transform(X_val_split)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "num_classes = len(np.unique(y_train_split))\n",
    "Y_train_encoded = one_hot_encode(y_train_split.to_numpy().flatten().astype(int), num_classes)\n",
    "\n",
    "model = MultivariateLogisticRegression(alpha=0.2, epochs=10000, reg_ridge=0.1)\n",
    "loss_vec = model.train(X_train_split_scaled, Y_train_encoded)\n",
    "\n",
    "# se suma 1 a la prediccion por notacion de kaggle\n",
    "y_pred = model.predict(X_val_split_scaled) + 1\n",
    "accuracy = accuracy_score(y_val_split, y_pred)\n",
    "\n",
    "y_val_pred = model.predict(X_val_split_scaled) + 1\n",
    "accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "\n",
    "print(classification_report(y_val_split, y_val_pred, target_names=labels_actions))\n",
    "print(f'Exactitud del modelo en validación: {accuracy * 100:.2f}%')\n",
    "\n",
    "y_test_pred = model.predict(X_test_scaled) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36506b-cbae-4f98-9e20-3eb7e0703aeb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4313e5-72ac-49bf-9985-41a3b05d97f6",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d35d91-3c9c-4022-9278-ec1805a01502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91356aff-b90d-4cc0-9d3c-810b7ae5d1f8",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb09890-ea96-478f-8d30-70c64051e3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5dd7ec1-40c8-4819-aa67-f77b1b15ab1a",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54841f6a-aa2a-45dc-89f0-e86c858243f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = norm_data(X_test.to_numpy())\n",
    "\n",
    "# Y_test_knn = kdtree.predict(X_test_norm)\n",
    "Y_test_knn = np.array(Y_test_knn)\n",
    "print(Y_test_knn.shape)\n",
    "print(np.unique(Y_test_knn))\n",
    "\n",
    "# Y_test_tree = dt.predict(X_test.to_numpy())\n",
    "# print(Y_test_tree.shape)\n",
    "# print(np.unique(Y_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bbdad9-d896-45fb-9c12-3787854e8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribiendo a csv\n",
    "output = \"results.csv\"\n",
    "\n",
    "result_csv = pd.DataFrame(Y_test_knn.astype(int))\n",
    "# result_csv = pd.DataFrame(Y_test_tree.astype(int))\n",
    "result_csv.head()\n",
    "result_csv = result_csv.reset_index()\n",
    "result_csv['index'] += 1\n",
    "\n",
    "result_csv.rename(columns={'index': 'ID', 0: 'y'}, inplace=True)\n",
    "result_csv.to_csv(output, index=False)\n",
    "print(f\"Wrote to: {output} !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
