\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}
    % Title
    \title{Human Activity Recognition Using Smartphones\\}

    % Authors
    \author{\textit{Kalos Lazo (100\%), Lucas Carranza (100\%), Benjamín Soto (100\%), José Osnayo}}
\maketitle

\section{Introduction}
En el presente documento se discute acerca de la resolución de un problema de clasificación supervisada a partir de un estudio realizado a un grupo de voluntarios de entre $19$ y $48$, mientras realizaban actividades cotidianas: \textit{caminar, subir escaleras, bajar escaleras, sentarse, levantarse y acostarse} se obtuvieron datos del acelómetro y giroscopio embebido sus teléfonos inteligentes: \textit{Samsung Galaxy SII}. Los datos fueron convertidos usando la librería TsFresh para extraer las características de las series temporales más importantes. Finalmente se usaron dos modelos de clasificación para predecir la actividad realizada según las características de la serie temporal.

\section{Conjunto de Datos}
\subsection{Exploración del Dataset}
Los datos utilizados en este proyecto contienen información extraída del teléfono: \textit{acelerómetro y giroscopio}. Esta información se provee en un archivo de extensión \texttt{.h5} que indica que es un formato jerárquico \texttt{HDF} y sirve para múltiples datasets. Para la data de entrenamiento se incluyeron consigo, en su jerarquía, 10 datasets con 7352 entradas que indican lo siguiente:

\begin{table}[htbp]
    \caption{Descripción de Variables}
    \begin{center}
        \begin{tabular}{|l|l|}
        \hline
        \textbf{Variable} & \textbf{Descripción} \\
        \hline
        \texttt{body\_acc\_x} & Señal de aceleración del cuerpo en el eje X.\\
        \hline
        \texttt{body\_acc\_y} & Señal de aceleración del cuerpo en el eje Y.\\
        \hline
        \texttt{body\_acc\_z} & Señal de aceleración del cuerpo en el eje Z.\\
        \hline
        \texttt{body\_gyro\_x} & Velocidad angular medida en el eje X.\\
        \hline
        \texttt{body\_gyro\_y} & Velocidad angular medida en el eje Y. \\
        \hline
        \texttt{body\_gyro\_z} & Velocidad angular medida en el eje Z. \\
        \hline
        \texttt{total\_acc\_x} & Señal de aceleración total en el eje X. \\
        \hline
        \texttt{total\_acc\_y} & Señal de aceleración total en el eje Y. \\
        \hline
        \texttt{total\_acc\_z} & Señal de aceleración total en el eje Z. \\
        \hline
        \texttt{y} & Etiquetas de actividad del 1 al 6. \\
        \hline
        \end{tabular}
        \label{tab1}
    \end{center}
\end{table}

Cada dataset (excepto \texttt{y}) cuenta con 128 columnas, donde cada una corresponde a la medida de cada variable en cierta unidad de tiempo.
Para la data de testing se incluyeron las mismas variables a excepción de \texttt{y} con 2947 entradas.

\subsection{Extracción de Features}
Para poder utilizar los datos para realizar la clasificación necesitamos convertir las series temporales a un conjunto de características. Para realizar esto se usó la librería TsFresh con su función \texttt{extract\_features} con los parámetros mínimos. Esto convirtió cada dataset de 128 timestamps a 9 características, por lo que se concatenaron para obtener un dataset de entrenamiento y testing de 81 características.

\textbf{PENDIENTE: Listar características extraídas en el anexo}

\section{Metodología}
% Explanation of the model, loss functions, and regularization techniques
Se utilizaron principalmente dos modelos en este proyecto: KNN usando KdTree y Regresión Logística con función Softmax.

\subsection{Justificación}
La razón por la que se usó KNN fue por la facilidad de su implementación para clasificación de múltiples clases, y se utilizó un KdTree para garantizar su eficiencia, ya que se deben calcular las distancias de más 2000 puntos de 81 dimensiones. Debido a que el número de dimensiones no es demasiado grande no hay problema al calcular las distancias.

Se probó la clasificación utilizando Decision Tree. Sin embargo debido a que los datos eran continuos, el splitting óptimo fue difícil de calcular. Esto resultó en una predicción sub-óptima con precisión de testing inferior a 20\%. Esto acompañado con el hecho de que se solían predecir solo 3 de las 6 clases, sugiere que este modelo generaba \textit{overfitting}.

Por ende, para aprovechar los datos continuos se utilizó Regresión Logística. Sin embargo, debido a que el modelo visto en clase solo permite clasificación binaria, se implementó una función Softmax para reemplazar la Sigmoidea, la cual permite realizar clasificación Multinomial.

\subsection{KNN}
\subsection{Regresión Logística}

\section{Implementación}
% Include the link to Colab or GitHub where the implementation can be found, avoiding direct
% code placement in the report. Define a seed to replicate the results. [Optional] Relevant implementation
% details can also be included (error handling, parallelization, etc.).
El código del proyecto se encuentra en el siguiente Repositorio de GitHub:


\textbf{Detalles de implementación:}

Durante la experimentación se usó paralelización al momento de realizar la extracción de features. Para la entrega final se eliminó la paralelización para garantizar la integridad y precisión de las características.

Se fijó la semilla aleatoria para ...

\section{Experimentación}
% Present results with graphs and/or tables, avoiding terminal screenshots
Se experimentaron principalmente con los dos modelos. Se utilizó K-Fold Cross-Validation para calcular la precisión de entrenamiento y validación usando múltiples Bases de Datos.

\subsection{Experimentación con KNN}

\subsection{Experimentación con Regresión Logística}


\section{Discusión}
% Interpretation of the obtained results and their relationship with the learned theory


\section{Conclusiones}
% Summary of results, limitations, and recommendations

\end{document}
